{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "mGbRjbl5gTUs",
        "outputId": "ce2e6e4d-7fc2-4734-a06c-9dff754768c9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/data.mat'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e6dda6b4dc8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdatafile\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'../data/data.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlabelfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/Label_Flevoland_15cls.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mlabel_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/data.mat'"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import os.path\n",
        "from argparse import RawTextHelpFormatter\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import socket\n",
        "import traceback\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from pandas import DataFrame\n",
        "from os import makedirs\n",
        "from tensorflow.keras import callbacks\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from typing import Optional, List, Union, Tuple\n",
        "from cvnn.utils import REAL_CAST_MODES, create_folder, transform_to_real_map_function\n",
        "from San_Francisco.sf_data_reader import SanFranciscoDataset\n",
        "from models.zhang_cnn import get_zhang_cnn_model\n",
        "import random\n",
        "from abc import ABC, abstractmethod\n",
        "import matplotlib.pyplot as plt\n",
        "import spectral.io.envi as envi\n",
        "import scipy.io\n",
        "from pdb import set_trace\n",
        "import tikzplotlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn\n",
        "from cvnn.utils import standarize, randomize, transform_to_real_map_function, create_folder\n",
        "from imageio import imread\n",
        "from pathlib import Path\n",
        "from os import path\n",
        "from typing import Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "root_path = \"/media/barrachina/data/datasets/PolSar/San Francisco/PolSF\"\n",
        "\n",
        "sys.path.insert(1, \"../\")\n",
        "if not path.exists(root_path):\n",
        "    raise FileNotFoundError(\"path of the san francisco dataset not found\")\n",
        "from dataset_reader import labels_to_rgb, SF_COLORS, PolsarDatasetHandler\n",
        "\n",
        "\n",
        "AVAILABLE_IMAGES = {\n",
        "    \"SF-AIRSAR\": {\"x1\": 0, \"y1\": 0, \"x2\": 1024, \"y2\": 900, \"y_inverse\": False},\n",
        "    \"SF-ALOS2\": {\"x1\": 736, \"y1\": 2832, \"x2\": 3520, \"y2\": 7888, \"y_inverse\": True},\n",
        "    # \"SF-GF3\": {\"x1\": 1144, \"y1\": 3464, \"x2\": 3448, \"y2\": 6376, \"y_inverse\": True},\n",
        "    \"SF-RS2\": {\"x1\": 661, \"y1\": 7326, \"x2\": 2041, \"y2\": 9126, \"y_inverse\": False},\n",
        "    # \"SF-RISAT\": {\"x1\": 2486, \"y1\": 4257, \"x2\": 7414, \"y2\": 10648, \"y_inverse\": False},   # RISAT is not Pol\n",
        "}\n",
        "\n",
        "\n",
        "class SanFranciscoDataset(PolsarDatasetHandler):\n",
        "\n",
        "    def __init__(self, dataset_name: str, mode: str, *args, **kwargs):\n",
        "        dataset_name = dataset_name.upper()\n",
        "        assert dataset_name in AVAILABLE_IMAGES, f\"Unknown data {dataset_name}.\"\n",
        "        super(SanFranciscoDataset, self).__init__(root_path=str(Path(root_path) / dataset_name),\n",
        "                                                  name=dataset_name, mode=mode, *args, **kwargs)\n",
        "\n",
        "    def print_ground_truth(self, t=None, *args, **kwargs):\n",
        "        if t is None:\n",
        "            t = self.get_image() if self.mode == \"t\" else None\n",
        "        super(SanFranciscoDataset, self).print_ground_truth(t=t, *args, **kwargs)\n",
        "\n",
        "    def get_sparse_labels(self):\n",
        "        labels = imread(Path(root_path) / self.name / (self.name + \"-label2d.png\"))\n",
        "        return labels\n",
        "\n",
        "    def get_image(self, save_image: bool = False) -> np.ndarray:\n",
        "        folder = \"SAN_FRANCISCO_\" + self.name[3:]\n",
        "        if self.mode == \"s\":\n",
        "            data = self.open_s_dataset(str(Path(root_path) / self.name / folder))\n",
        "        elif self.mode == \"t\":\n",
        "            data = self.open_t_dataset_t3(str(Path(root_path) / self.name / folder / \"T4\"))\n",
        "        else:\n",
        "            raise ValueError(f\"Mode {self.mode} not supported.\")\n",
        "        data = data[\n",
        "               AVAILABLE_IMAGES[self.name][\"y1\"]:AVAILABLE_IMAGES[self.name][\"y2\"],\n",
        "               AVAILABLE_IMAGES[self.name][\"x1\"]:AVAILABLE_IMAGES[self.name][\"x2\"]\n",
        "               ]\n",
        "        if AVAILABLE_IMAGES[self.name][\"y_inverse\"]:\n",
        "            data = np.flip(data, axis=0)\n",
        "        return data\n",
        "\n",
        "BUFFER_SIZE = 32000\n",
        "\n",
        "cao_dataset_parameters = {\n",
        "    'validation_split': 0.1,  # Section 3.3.2\n",
        "    'batch_size': 30,  # Section 3.3.2\n",
        "    'sliding_window_size': 128,  # Section 3.3.2\n",
        "    'sliding_window_stride': 25,  # Section 3.3.2\n",
        "    'window_for_mlp': 32  # Section 3.4\n",
        "}\n",
        "\n",
        "zhang_dataset_parameters = {\n",
        "    'validation_split': 0.1,\n",
        "    'test_split': 0.9,\n",
        "    'batch_size': 100,\n",
        "    'sliding_window_size': 12,\n",
        "    'sliding_window_stride': 1\n",
        "}\n",
        "\n",
        "OBER_COLORS = np.array([\n",
        "    [1, 0.349, 0.392],      # Red; Built-up Area\n",
        "    [0.086, 0.858, 0.576],  # Green; Wood Land\n",
        "    [0.937, 0.917, 0.352],  # Yellow; Open Area\n",
        "    [0, 0.486, 0.745]\n",
        "])\n",
        "\n",
        "BRET_COLORS = np.array([\n",
        "    [0.086, 0.858, 0.576],  # Green; Forest\n",
        "    [0, 0.486, 0.745],  # Blue; Piste\n",
        "    [1, 0.349, 0.392],  # Red; Built-up Area\n",
        "    [0.937, 0.917, 0.352],  # Yellow; Open Area\n",
        "])\n",
        "\n",
        "SF_COLORS = {\n",
        "    \"SF-ALOS2\": [\n",
        "        [132, 112, 255],\n",
        "        [0, 0, 255],\n",
        "        [0, 255, 0],\n",
        "        [192, 0, 0],\n",
        "        [0, 255, 255],\n",
        "        [255, 255, 0]\n",
        "    ],\n",
        "    \"SF-GF3\": [\n",
        "        [132, 112, 255],\n",
        "        [0, 0, 255],\n",
        "        [0, 255, 0],\n",
        "        [192, 0, 0],\n",
        "        [0, 255, 255],\n",
        "        [255, 255, 0]\n",
        "    ],\n",
        "    \"SF-RISAT\": [\n",
        "        [132, 112, 255],\n",
        "        [0, 0, 255],\n",
        "        [0, 255, 0],\n",
        "        [192, 0, 0],\n",
        "        [0, 255, 255],\n",
        "        [255, 255, 0]\n",
        "    ],\n",
        "    \"SF-RS2\": [\n",
        "        [0, 0, 255],\n",
        "        [0, 255, 0],\n",
        "        [255, 0, 0],\n",
        "        [255, 255, 0],\n",
        "        [255, 0, 255]\n",
        "    ],\n",
        "    \"SF-AIRSAR\": [\n",
        "        [0, 255, 255],\n",
        "        [255, 255, 0],\n",
        "        [0, 0, 255],\n",
        "        [255, 0, 0],\n",
        "        [0, 255, 0]\n",
        "    ]\n",
        "}\n",
        "\n",
        "COLORS = {\"BRET\": BRET_COLORS, \"OBER\": OBER_COLORS, **SF_COLORS}\n",
        "\n",
        "# https://imagecolorpicker.com/en\n",
        "FLEVOLAND = np.array([\n",
        "    [255, 0, 0],  # Red; Steambeans\n",
        "    [90, 11, 226],  # Purple; Peas\n",
        "    [0, 131, 74],  # Green; Forest\n",
        "    [0, 252, 255],  # Teal; Lucerne\n",
        "    [255, 182, 228],  # Pink; Wheat\n",
        "    [184, 0, 255],  # Magenta; Beet\n",
        "    [254, 254, 0],  # Yellow; Potatoes\n",
        "    [170, 138, 79],  # Brown; Bare Soil\n",
        "    [1, 254, 3],  # Light green; Grass\n",
        "    [255, 127, 0],  # Orange; Rapeseed\n",
        "    [146, 0, 1],  # Bordeaux; Barley\n",
        "    [191, 191, 255],  # Lila; Wheat 2\n",
        "    [191, 255, 192],  # Marine Green; Wheat 3\n",
        "    [0, 0, 254],  # Blue; Water\n",
        "    [255, 217, 160]  # Beige; Buildings\n",
        "])\n",
        "FLEVOLAND = np.divide(FLEVOLAND, 255.0).astype(np.float32)\n",
        "\n",
        "FLEVOLAND_2 = np.array([\n",
        "    [255, 128, 0],  # Orange; Potatoes\n",
        "    [138, 42, 116],  # Dark Purple; Fruit\n",
        "    [0, 0, 255],  # Blue; Oats\n",
        "    [255, 0, 0],  # Red; Beet\n",
        "    [120, 178, 215],  # Light Blue; Barley\n",
        "    [0, 102, 255],  # Middle Blue; Onions\n",
        "    [251, 232, 45],  # Yellow; Wheat\n",
        "    [1, 255, 3],  # Light green; Beans\n",
        "    [204, 102, 225],  # Magenta; Peas\n",
        "    [0, 204, 102],  # Green; Maize\n",
        "    [204, 255, 204],  # Palid Green; Flax\n",
        "    [204, 1, 102],  # Bordeaux; Rapeseed\n",
        "    [255, 204, 204],  # Beige; Gress\n",
        "    [102, 0, 204],  # Purple; Bare Soil\n",
        "\n",
        "])\n",
        "FLEVOLAND_2 = np.divide(FLEVOLAND_2, 255.0).astype(np.float32)\n",
        "\n",
        "DEFAULT_PLOTLY_COLORS = [\n",
        "    [31, 119, 180],  # Blue\n",
        "    [255, 127, 14],  # Orange\n",
        "    [44, 160, 44],  # Green\n",
        "    [214, 39, 40],\n",
        "    [148, 103, 189], [140, 86, 75],\n",
        "    [227, 119, 194], [127, 127, 127],\n",
        "    [188, 189, 34], [23, 190, 207]\n",
        "]\n",
        "DEFAULT_PLOTLY_COLORS = np.divide(DEFAULT_PLOTLY_COLORS, 255.0).astype(np.float32)\n",
        "\n",
        "\n",
        "def flip(data, labels):\n",
        "    \"\"\"\n",
        "    Flip augmentation\n",
        "    :param data: Image to flip\n",
        "    :param labels: Image labels\n",
        "    :return: Augmented image\n",
        "    \"\"\"\n",
        "    data = tf.image.random_flip_left_right(data)\n",
        "    # data = tf.image.random_flip_up_down(data)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "def sparse_to_categorical_1D(labels) -> np.ndarray:\n",
        "    classes = np.max(labels)\n",
        "    ground_truth = np.zeros(labels.shape + (classes,), dtype=float)\n",
        "    for i in range(labels.shape[0]):\n",
        "        if labels[i] != 0:\n",
        "            ground_truth[i, labels[i] - 1] = 1.\n",
        "    return ground_truth\n",
        "\n",
        "\n",
        "def pauli_rgb_map_plot(labels, dataset_name: str, t: Optional[np.ndarray] = None, path=None, mask=None, ax=None):\n",
        "    labels_rgb = labels_to_rgb(labels, colors=COLORS[dataset_name], mask=mask)\n",
        "    fig = None\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    alpha = 1.\n",
        "    # set_trace()\n",
        "    # if t is not None:\n",
        "    #     alpha = 0.4\n",
        "    #     rgb = np.stack([t[:, :, 0], t[:, :, 1], t[:, :, 2]], axis=-1).astype(np.float32)\n",
        "    #     ax.imshow(rgb)\n",
        "    ax.imshow(labels_rgb, alpha=alpha)\n",
        "    if fig is not None and path is not None:\n",
        "        path = str(path)\n",
        "        if len(path.split(\".\")) < 2:\n",
        "            path = path + \".png\"\n",
        "        fig.savefig(path)\n",
        "    else:\n",
        "        plt.show()\n",
        "    if fig is not None:\n",
        "        plt.close(fig)\n",
        "\n",
        "\n",
        "def labels_to_rgb(labels, showfig=False, savefig: Optional[str] = None, colors=None, mask=None, format: str = '.png') \\\n",
        "        -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Transforms the labels to a RGB format so it can be drawn as images\n",
        "    :param labels: The labels to be transformed to rgb\n",
        "    :param showfig: boolean. If true it will show the generated ground truth image\n",
        "    :param savefig: A string. String with the file to be saved of the generated ground truth image\n",
        "    :param colors: Color palette to be used. Must be at least size of the labels. TODO: Some kind of check for this?\n",
        "    :param mask: If the mask is passed it will remove the pixels (black) when mask == 0\n",
        "    :return: numpy array of the ground truth RGB image\n",
        "    \"\"\"\n",
        "    if len(labels.shape) == 3:\n",
        "        labels = np.argmax(labels, axis=-1) + 1\n",
        "    elif len(labels.shape) != 2:\n",
        "        raise ValueError(f\"Expected labels to be rank 3 or 2, received rank {len(labels.shape)}.\")\n",
        "    if colors is None:\n",
        "        if np.max(labels) == 3:\n",
        "            print(\"Using Oberpfaffenhofen dataset colors\")\n",
        "            colors = OBER_COLORS\n",
        "        elif np.max(labels) == 4:\n",
        "            print(\"Using Bretigny dataset colors\")\n",
        "            colors = BRET_COLORS\n",
        "        elif np.max(labels) == 15:\n",
        "            print(\"Using Flevoland dataset colors\")\n",
        "            colors = FLEVOLAND\n",
        "        elif np.max(labels) == 14:\n",
        "            print(\"Using Flevoland 2 dataset colors\")\n",
        "            colors = FLEVOLAND_2\n",
        "        else:\n",
        "            print(\"Using Plotly dataset colors\")\n",
        "            colors = DEFAULT_PLOTLY_COLORS\n",
        "    ground_truth = np.zeros(labels.shape + (3,), dtype=float if np.max(colors) <= 1 else np.uint8)  # 3 channels for RGB\n",
        "    for i in range(labels.shape[0]):\n",
        "        for j in range(labels.shape[1]):\n",
        "            if labels[i, j] != 0:\n",
        "                # try:\n",
        "                ground_truth[i, j] = colors[labels[i, j] - 1]\n",
        "                # except Exception as e:\n",
        "                #     import pdb; pdb.set_trace()\n",
        "    if mask is not None:\n",
        "        ground_truth[mask == 0] = [0, 0, 0]\n",
        "    if showfig:\n",
        "        plt.imshow(ground_truth)\n",
        "        # plt.show()\n",
        "    if savefig is not None:\n",
        "        assert isinstance(savefig, str)\n",
        "        if format == \".tex\":\n",
        "            tikzplotlib.save(savefig + \".tex\")\n",
        "        else:\n",
        "            plt.imsave(savefig + format, ground_truth)\n",
        "    return ground_truth\n",
        "\n",
        "\n",
        "class PolsarDatasetHandler(ABC):\n",
        "\n",
        "    def __init__(self, root_path: str, name: str, mode: str, complex_mode: bool = True, real_mode: str = 'real_imag',\n",
        "                 normalize: bool = False, balance_dataset: bool = False, classification: bool = False):\n",
        "        self.root_path = Path(str(root_path))\n",
        "        self.name = name\n",
        "        assert mode.lower() in {\"s\", \"t\", \"k\"}\n",
        "        self.mode = mode.lower()\n",
        "        self.real_mode = real_mode.lower()\n",
        "        self.complex_mode = complex_mode    # TODO: Best practice to leave it outside\n",
        "        self.classification = classification\n",
        "        # self.image, self.labels, self.sparse_labels = self.open_image()\n",
        "        # assert self.image.shape[:2] == self.labels.shape[:2]\n",
        "        # if normalize:\n",
        "        #     self.image, _ = tf.linalg.normalize(self.image, axis=[0, 1])\n",
        "        self.balance_dataset = balance_dataset\n",
        "        # if balance_dataset and not classification:\n",
        "        #     self._balance_image()\n",
        "        # self.weights = self._get_weights(self.labels)\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_image(self) -> np.ndarray:\n",
        "        pass\n",
        "\n",
        "    def get_labels(self) -> np.ndarray:\n",
        "        return self.sparse_to_categorical_2D(self.get_sparse_labels())\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_sparse_labels(self) -> np.ndarray:\n",
        "        pass\n",
        "\n",
        "    def get_dataset(self, method: str, percentage: Union[Tuple[float], float] = 0.2,\n",
        "                    size: int = 128, stride: int = 25, shuffle: bool = True, pad=\"same\",\n",
        "                    savefig: Optional[str] = None, orientation: str = \"vertical\", data_augment: bool = False,\n",
        "                    batch_size: int = cao_dataset_parameters['batch_size'], use_tf_dataset=False):\n",
        "        if method == \"random\":\n",
        "            x_patches, y_patches = self._get_shuffled_dataset(size=size, stride=stride, pad=pad, percentage=percentage,\n",
        "                                                              shuffle=shuffle,\n",
        "                                                              classification=self.classification)\n",
        "        elif method == \"separate\":\n",
        "            x_patches, y_patches = self._get_separated_dataset(percentage=percentage, size=size, stride=stride, pad=pad,\n",
        "                                                               savefig=savefig, orientation=orientation,\n",
        "                                                               shuffle=shuffle,\n",
        "                                                               classification=self.classification)\n",
        "        elif method == \"single_separated_image\":\n",
        "            assert self.classification, f\"Can't apply classification to the full image.\"\n",
        "            x_patches, y_patches = self._get_single_image_separated_dataset(percentage=percentage, savefig=savefig,\n",
        "                                                                            orientation=orientation, pad=True)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown dataset method {method}\")\n",
        "        if use_tf_dataset:\n",
        "            ds_list = [self._transform_to_tensor(x, y, batch_size=batch_size,\n",
        "                                                 data_augment=data_augment if i == 0 else False, shuffle=shuffle)\n",
        "                       for i, (x, y) in enumerate(zip(x_patches, y_patches))]\n",
        "        else:\n",
        "            if self.complex_mode:\n",
        "                ds_list = [(x, y) for i, (x, y) in enumerate(zip(x_patches, y_patches))]\n",
        "            else:\n",
        "                ds_list = [transform_to_real_map_function(x, y, self.real_mode)\n",
        "                           for i, (x, y) in enumerate(zip(x_patches, y_patches))]\n",
        "        return ds_list\n",
        "\n",
        "    \"\"\"\n",
        "        PRIVATE\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_percentage(percentage) -> List[float]:\n",
        "        if isinstance(percentage, int):\n",
        "            assert percentage == 1\n",
        "            percentage = (1.,)\n",
        "        if isinstance(percentage, float):\n",
        "            if percentage == 1:\n",
        "                percentage = (1.,)\n",
        "            elif 0 < percentage < 1:\n",
        "                percentage = (1 - percentage, percentage)\n",
        "            else:\n",
        "                raise ValueError(f\"Percentage must be 0 < percentage < 1, received {percentage}\")\n",
        "        else:\n",
        "            percentage = list(percentage)\n",
        "            assert sum(percentage) == 1., f\"percentage must add to 1, \" \\\n",
        "                                          f\"but it adds to sum{percentage} = {sum(percentage)}\"\n",
        "        return percentage\n",
        "\n",
        "    @staticmethod\n",
        "    def _pad_image(image, labels):\n",
        "        first_dim_pad = int(2 ** 5 * np.ceil(image.shape[0] / 2 ** 5)) - image.shape[0]\n",
        "        second_dim_pad = int(2 ** 5 * np.ceil(image.shape[1] / 2 ** 5)) - image.shape[1]\n",
        "        paddings = [\n",
        "            [int(np.ceil(first_dim_pad / 2)), int(np.floor(first_dim_pad / 2))],\n",
        "            [int(np.ceil(second_dim_pad / 2)), int(np.floor(second_dim_pad / 2))],\n",
        "            [0, 0]\n",
        "        ]\n",
        "        image = tf.pad(image, paddings)\n",
        "        labels = tf.pad(labels, paddings)\n",
        "        return image, labels\n",
        "\n",
        "    def _slice_dataset(self, percentage: tuple, orientation: str, savefig: Optional[str]):\n",
        "        orientation = orientation.lower()\n",
        "        percentage = self._parse_percentage(percentage)\n",
        "        image = self.get_image()\n",
        "        labels = self.get_labels()\n",
        "        sparse_labels = self.get_sparse_labels()\n",
        "        if orientation == \"horizontal\":\n",
        "            total_length = image.shape[1]\n",
        "        elif orientation == \"vertical\":\n",
        "            total_length = image.shape[0]\n",
        "        else:\n",
        "            raise ValueError(f\"Orientation {orientation} unknown.\")\n",
        "        th = 0\n",
        "        x_slice = []\n",
        "        y_slice = []\n",
        "        mask_slice = []\n",
        "        for per in percentage:\n",
        "            slice_1 = slice(th, th + int(total_length * per))\n",
        "            th += int(total_length * per)\n",
        "            if orientation == \"horizontal\":\n",
        "                x_slice.append(image[:, slice_1])\n",
        "                y_slice.append(labels[:, slice_1])\n",
        "                mask_slice.append(sparse_labels[:, slice_1])\n",
        "            else:\n",
        "                x_slice.append(image[slice_1])\n",
        "                y_slice.append(labels[slice_1])\n",
        "                mask_slice.append(sparse_labels[slice_1])\n",
        "        if savefig:\n",
        "            slices_names = [\n",
        "                'train_ground_truth', 'val_ground_truth', 'test_ground_truth'\n",
        "            ]\n",
        "            for i, y in enumerate(y_slice):\n",
        "                self.print_ground_truth(label=y, t=x_slice[i], mask=mask_slice[i], path=str(savefig) + slices_names[i])\n",
        "        return x_slice, y_slice\n",
        "\n",
        "    def _transform_to_tensor(self, x, y, batch_size: int, data_augment: bool = False, shuffle=True):\n",
        "        ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "        if shuffle:\n",
        "            ds = ds.shuffle(buffer_size=BUFFER_SIZE)\n",
        "        ds = ds.batch(batch_size)\n",
        "        if data_augment:\n",
        "            ds = ds.map(flip)\n",
        "        if not self.complex_mode:\n",
        "            ds = ds.map(lambda img, labels: transform_to_real_map_function(img, labels, self.real_mode))\n",
        "        return ds\n",
        "\n",
        "    @staticmethod\n",
        "    def balanced_test_split(x_all, y_all, test_size, shuffle):\n",
        "        x_train_per_class, x_test_per_class, y_train_per_class, y_test_per_class = [], [], [], []\n",
        "        sparse_y = np.argmax(y_all, axis=-1)\n",
        "        for cls in range(y_all.shape[-1]):\n",
        "            x_train, x_test, y_train, y_test = train_test_split(x_all[sparse_y == cls], y_all[sparse_y == cls],\n",
        "                                                                train_size=int(\n",
        "                                                                    (1-test_size) * y_all.shape[0] / y_all.shape[-1]),\n",
        "                                                                shuffle=shuffle)\n",
        "            x_train_per_class.append(x_train)\n",
        "            x_test_per_class.append(x_test)\n",
        "            y_train_per_class.append(y_train)\n",
        "            y_test_per_class.append(y_test)\n",
        "        x_train = np.concatenate(x_train_per_class)\n",
        "        x_test = np.concatenate(x_test_per_class)\n",
        "        y_train = np.concatenate(y_train_per_class)\n",
        "        y_test = np.concatenate(y_test_per_class)\n",
        "        return x_train, x_test, y_train, y_test\n",
        "\n",
        "    def _separate_dataset(self, patches, label_patches, percentage: List[float], shuffle: bool = True) \\\n",
        "            -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
        "        \"\"\"\n",
        "        :param patches: data patches\n",
        "        :param label_patches: label patches\n",
        "        :param percentage: list of percentages for each value,\n",
        "            example [0.9, 0.02, 0.08] to get 90% train, 2% val and 8% test.\n",
        "        :param shuffle: Shuffle dataset before split.\n",
        "        :return: tuple of two lists of size = len(percentage), one with data x and other with labels y.\n",
        "        \"\"\"\n",
        "        percentage = self._parse_percentage(percentage)\n",
        "        x_test = patches\n",
        "        y_test = label_patches\n",
        "        percentage = list(percentage)       # need it to be mutable\n",
        "        x = []\n",
        "        y = []\n",
        "        for i, per in enumerate(percentage[:-1]):\n",
        "            if self.classification and self.balance_dataset:\n",
        "                x_train, x_test, y_train, y_test = self.balanced_test_split(x_test, y_test, test_size=1 - per,\n",
        "                                                                            shuffle=shuffle)\n",
        "            else:\n",
        "                x_train, x_test, y_train, y_test = train_test_split(x_test, y_test, test_size=1-per,\n",
        "                                                                    shuffle=True if self.classification else shuffle,\n",
        "                                                                    stratify=y_test if self.classification else None)\n",
        "            percentage[i+1:] = [value / (1-percentage[i]) for value in percentage[i+1:]]\n",
        "            x.append(x_train)\n",
        "            y.append(y_train)\n",
        "        x.append(x_test)\n",
        "        y.append(y_test)\n",
        "        x[0], y[0] = self._remove_empty_image(data=x[0], labels=y[0])\n",
        "        return x, y\n",
        "\n",
        "    @staticmethod\n",
        "    def _to_classification(x, y, mask=False):\n",
        "        y = np.reshape(y[:, y.shape[1] // 2, y.shape[2] // 2, :], newshape=(y.shape[0], y.shape[-1]))\n",
        "        # assert [np.all(y_patches_class[i][:] == y_patches[i][0][0][:]) for i in range(len(y_patches_class))]\n",
        "        # 2. Remove empty pixels\n",
        "        if mask:        # TODO: Remove this?\n",
        "            mask = np.invert(np.all(y == 0, axis=-1))\n",
        "            x = tf.boolean_mask(x, mask).numpy()\n",
        "            y = tf.boolean_mask(y, mask).numpy()\n",
        "        return x, y\n",
        "\n",
        "    # Get dataset\n",
        "    def _get_shuffled_dataset(self, size: int = 128, stride: int = 25, percentage: List[float] = (0.8, 0.2),\n",
        "                              shuffle: bool = True, pad=\"same\",\n",
        "                              classification: bool = False) -> (tf.data.Dataset, tf.data.Dataset):\n",
        "        \"\"\"\n",
        "        Applies the sliding window operations getting smaller images of a big image T.\n",
        "        Splits dataset into train and test.\n",
        "        :param size: Size of the window to be used on the sliding window operation.\n",
        "        :param stride:\n",
        "        :param percentage: float. Percentage of examples to be used for the test set [0, 1]\n",
        "        :return: a Tuple of tf.Datasets (train_dataset, test_dataset)\n",
        "        \"\"\"\n",
        "        patches, label_patches = self.apply_sliding(size=size, stride=stride, pad=pad, classification=classification)\n",
        "        # del T, labels  # Free up memory\n",
        "        x, y = self._separate_dataset(patches, label_patches, percentage, shuffle=shuffle)\n",
        "        return x, y\n",
        "\n",
        "    def _get_separated_dataset(self, percentage: tuple, size: int = 128, stride: int = 25, shuffle: bool = True, pad=0,\n",
        "                               savefig: Optional[str] = None, orientation: str = \"vertical\", classification=False):\n",
        "        images, labels = self._slice_dataset(percentage=percentage, savefig=savefig, orientation=orientation)\n",
        "        # train_slice_label = _balance_image(train_slice_label)\n",
        "        if isinstance(size, int):\n",
        "            size = (size, size)\n",
        "        else:\n",
        "            size = tuple(size)\n",
        "            assert len(size) == 2\n",
        "        for i in range(0, len(labels)):\n",
        "            images[i], labels[i] = self._sliding_window_operation(images[i], labels[i],\n",
        "                                                                  size=size, stride=stride,\n",
        "                                                                  pad=self._parse_pad(pad, size))   # TODO: Use apply\n",
        "            images[i], labels[i] = self._remove_empty_image(data=images[i], labels=labels[i])\n",
        "            if classification:      # TODO: TEST THIS\n",
        "                images[i], labels[i] = self._to_classification(x=images[i], y=labels[i])\n",
        "            if shuffle:  # No need to shuffle the rest\n",
        "                images[i], labels[i] = sklearn.utils.shuffle(images[i], labels[i])\n",
        "        return images, labels\n",
        "\n",
        "    def _get_single_image_separated_dataset(self, percentage: tuple, savefig: Optional[str] = None,\n",
        "                                            orientation: str = \"vertical\", pad: bool = False):\n",
        "        x, y = self._slice_dataset(percentage=percentage, savefig=savefig, orientation=orientation)\n",
        "        for i in range(0, len(y)):\n",
        "            if pad:\n",
        "                x[i], y[i] = self._pad_image(x[i], y[i])\n",
        "            x[i] = tf.expand_dims(x[i], axis=0)\n",
        "            y[i] = tf.expand_dims(y[i], axis=0)\n",
        "        return x, y\n",
        "\n",
        "    @staticmethod\n",
        "    def _remove_empty_image(data, labels):\n",
        "        if len(labels.shape) == 4:\n",
        "            mask = np.invert(np.all(np.all(labels == 0, axis=-1), axis=(1, 2)))\n",
        "        elif len(labels.shape) == 2:\n",
        "            mask = np.invert(np.all(labels == 0, axis=-1))\n",
        "        else:\n",
        "            raise ValueError(f\"Ups, shape of labels of size {len(labels.shape)} not supported.\")\n",
        "        masked_filtered_data = tf.reshape(tf.boolean_mask(data, mask), shape=(-1,) + data.shape[1:])\n",
        "        masked_filtered_labels = tf.boolean_mask(labels, mask)\n",
        "        # filtered_data = []\n",
        "        # filtered_labels = []\n",
        "        # for i in range(0, len(labels)):\n",
        "        #     if not np.all(labels[i] == 0):\n",
        "        #         filtered_data.append(data[i])\n",
        "        #         filtered_labels.append(labels[i])\n",
        "        # filtered_data = np.array(filtered_data)\n",
        "        # filtered_labels = np.array(filtered_labels)\n",
        "        # assert np.all(masked_filtered_data.numpy() == filtered_data)\n",
        "        # assert np.all(masked_filtered_labels.numpy() == filtered_labels)\n",
        "        # set_trace()\n",
        "        return masked_filtered_data, masked_filtered_labels\n",
        "\n",
        "    # BALANCE DATASET\n",
        "    @staticmethod\n",
        "    def _select_random(img, value: int, total: int):\n",
        "        \"\"\"\n",
        "        Gets an image with different values and returns a boolean matrix with a total number of True equal to the total\n",
        "            parameter where all True are located in the same place where the img has the value passed as parameter\n",
        "        :param img: Image to be selected\n",
        "        :param value: Value to be matched\n",
        "        :param total:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        assert len(img.shape) == 2\n",
        "        flatten_img = np.reshape(img, tf.math.reduce_prod(img.shape).numpy())\n",
        "        random_indx = np.random.permutation(len(flatten_img))\n",
        "        mixed_img = flatten_img[random_indx]\n",
        "        selection_mask = np.zeros(shape=img.shape)\n",
        "        selected = 0\n",
        "        indx = 0\n",
        "        saved_indexes = []\n",
        "        while selected < total:\n",
        "            val = mixed_img[indx]\n",
        "            if val == value:\n",
        "                selected += 1\n",
        "                saved_indexes.append(random_indx[indx])\n",
        "                assert img[int(random_indx[indx] / img.shape[1])][random_indx[indx] % img.shape[1]] == value\n",
        "                selection_mask[int(random_indx[indx] / img.shape[1])][random_indx[indx] % img.shape[1]] = 1\n",
        "            indx += 1\n",
        "        return selection_mask.astype(bool)\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self._get_weights(self.get_labels())\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_weights(labels):\n",
        "        classes = tf.argmax(labels, axis=-1)\n",
        "        mask = np.all((labels == tf.zeros(shape=labels.shape[-1])), axis=-1)\n",
        "        classes = tf.where(mask, classes, classes + 1)  # Increment classes, now 0 = no label\n",
        "        totals = [tf.math.reduce_sum((classes == cls).numpy().astype(int)).numpy() for cls in\n",
        "                  range(1, tf.math.reduce_max(classes).numpy() + 1)]\n",
        "        return max(totals) / totals\n",
        "\n",
        "    \"\"\"\n",
        "        PUBLIC\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_pad(pad, kernel_size):\n",
        "        if isinstance(pad, int):\n",
        "            pad = ((pad, pad), (pad, pad))\n",
        "        elif isinstance(pad, str):\n",
        "            if pad.lower() == \"same\":\n",
        "                pad = tuple([(w // 2, (w - 1) // 2) for w in kernel_size])\n",
        "            elif pad.lower() == \"valid\":\n",
        "                pad = ((0, 0), (0, 0))\n",
        "            else:\n",
        "                raise ValueError(f\"padding: {pad} not recognized. Possible values are 'valid' or 'same'\")\n",
        "        else:\n",
        "            pad = list(pad)\n",
        "            assert len(pad) == 2\n",
        "            for indx in range(2):\n",
        "                if isinstance(pad[indx], int):\n",
        "                    pad[indx] = (pad[indx], pad[indx])\n",
        "                else:\n",
        "                    pad[indx] = tuple(pad[indx])\n",
        "                    assert len(pad[indx]) == 2\n",
        "            pad = tuple(pad)\n",
        "        return pad\n",
        "\n",
        "    def apply_sliding(self, size: Union[int, Tuple[int, int]] = 128, stride: int = 25, pad=\"same\",\n",
        "                      classification: bool = False, remove_unlabeled: bool = False):\n",
        "        image = self.get_image()\n",
        "        labels = self.get_labels()\n",
        "        if isinstance(size, int):\n",
        "            size = (size, size)\n",
        "        else:\n",
        "            size = tuple(size)\n",
        "            assert len(size) == 2\n",
        "        pad = self._parse_pad(pad, size)\n",
        "        temp_path = self.root_path / \"dataset_preprocess_cache\"\n",
        "        os.makedirs(str(temp_path), exist_ok=True)\n",
        "        config_string = f\"{'cls' if classification else 'seg'}_{self.name.lower()}_window{size}_stride{stride}_pad{pad}\"\n",
        "        if os.path.isfile(temp_path / (config_string + \"_patches\")):\n",
        "            patches = np.load(str(temp_path / (config_string + \"_patches.npy\")))\n",
        "            label_patches = np.load(str(temp_path / (config_string + \"_labels.npy\")))\n",
        "        else:\n",
        "            patches, label_patches = self._sliding_window_operation(image, labels, size=size, stride=stride,\n",
        "                                                                    pad=pad)\n",
        "            # print(f\"patches shape after sliding window op{patches.shape}\")\n",
        "            np.save(str(temp_path / (\"seg\" + config_string[3:] + \"_patches.npy\")), patches)\n",
        "            np.save(str(temp_path / (\"seg\" + config_string[3:] + \"_labels.npy\")), label_patches)\n",
        "            if classification:\n",
        "                patches, label_patches = self._to_classification(x=patches, y=label_patches, mask=remove_unlabeled)\n",
        "                np.save(str(temp_path / (\"cls\" + config_string[3:] + \"_patches.npy\")), patches)\n",
        "                np.save(str(temp_path / (\"cls\" + config_string[3:] + \"_labels.npy\")), label_patches)\n",
        "        # print(f\"patches shape before going out of apply slifing {patches.shape}\")\n",
        "        return patches, label_patches\n",
        "\n",
        "    # Utils\n",
        "    @staticmethod\n",
        "    def _sliding_window_operation(im, lab, size: Tuple[int, int], stride: int,\n",
        "                                  pad: Tuple[Tuple[int, int], Tuple[int, int]],\n",
        "                                  segmentation: bool = True) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Extracts many sub-images from one big image. Labels included.\n",
        "        Using the Sliding Window Operation defined in:\n",
        "            https://www.mdpi.com/2072-4292/10/12/1984\n",
        "        :param im: Image dataset\n",
        "        :param lab: pixel-wise labels dataset\n",
        "        :param size: Size of the desired mini new images\n",
        "        :param stride: stride between images, use stride=size for images not to overlap\n",
        "        :param pad: Pad borders\n",
        "        :return: tuple of numpy arrays (tiles, label_tiles)\n",
        "        \"\"\"\n",
        "        tiles = []\n",
        "        label_tiles = []\n",
        "        im = np.pad(im, (pad[0], pad[1], (0, 0)))\n",
        "        lab = np.pad(lab, (pad[0], pad[1], (0, 0)))\n",
        "        assert im.shape[0] > size[0] and im.shape[1] > size[1], f\"Image shape ({im.shape[0]}x{im.shape[1]}) \" \\\n",
        "                                                                f\"is smaller than the window to apply \" \\\n",
        "                                                                f\"({size[0]}x{size[1]})\"\n",
        "        for x in range(0, im.shape[0] - size[0] + 1, stride):\n",
        "            for y in range(0, im.shape[1] - size[1] + 1, stride):\n",
        "                slice_x = slice(x, x + size[0])\n",
        "                slice_y = slice(y, y + size[1])\n",
        "                tiles.append(im[slice_x, slice_y])\n",
        "                if segmentation:\n",
        "                    label_tiles.append(lab[slice_x, slice_y])\n",
        "                else:\n",
        "                    label_tiles.append(lab[x + int(size[0] / 2), y + int(size[1] / 2)])\n",
        "        assert np.all([p.shape == (size[0], size[1], im.shape[2]) for p in tiles])\n",
        "        # assert np.all([p.shape == (size, size, lab.shape[2]) for p in label_tiles])\n",
        "        # if not pad:  # If not pad then use equation 7 of https://www.mdpi.com/2072-4292/10/12/1984\n",
        "        #     assert int(np.shape(tiles)[0]) == int(\n",
        "        #         (np.floor((im.shape[0] - size[0]) / stride) + 1) * (np.floor((im.shape[1] - size[1]) / stride) + 1))\n",
        "        # print(f\"tiles shape before going out of sliding window op {np.array(tiles).shape}\")\n",
        "        return np.array(tiles), np.array(label_tiles)\n",
        "\n",
        "    @staticmethod\n",
        "    def sparse_to_categorical_2D(labels) -> np.ndarray:\n",
        "        classes = np.max(labels)\n",
        "        ground_truth = np.zeros(labels.shape + (classes,), dtype=float)\n",
        "        for i in range(labels.shape[0]):\n",
        "            for j in range(labels.shape[1]):\n",
        "                if labels[i, j] != 0:\n",
        "                    ground_truth[i, j, labels[i, j] - 1] = 1.\n",
        "        return ground_truth\n",
        "\n",
        "    # Open with path\n",
        "    @staticmethod\n",
        "    def open_t_dataset_t3(path: str):\n",
        "        path = Path(path)\n",
        "        first_read = standarize(envi.open(path / 'T11.bin.hdr', path / 'T11.bin').read_band(0))\n",
        "        T = np.zeros(first_read.shape + (6,), dtype=complex)\n",
        "\n",
        "        # Diagonal\n",
        "        T[:, :, 0] = first_read\n",
        "        T[:, :, 1] = standarize(envi.open(path / 'T22.bin.hdr', path / 'T22.bin').read_band(0))\n",
        "        T[:, :, 2] = standarize(envi.open(path / 'T33.bin.hdr', path / 'T33.bin').read_band(0))\n",
        "\n",
        "        # Upper part\n",
        "        T[:, :, 3] = standarize(envi.open(path / 'T12_real.bin.hdr', path / 'T12_real.bin').read_band(0) + \\\n",
        "                                1j * envi.open(path / 'T12_imag.bin.hdr', path / 'T12_imag.bin').read_band(0))\n",
        "        T[:, :, 4] = standarize(envi.open(path / 'T13_real.bin.hdr', path / 'T13_real.bin').read_band(0) + \\\n",
        "                                1j * envi.open(path / 'T13_imag.bin.hdr', path / 'T13_imag.bin').read_band(0))\n",
        "        T[:, :, 5] = standarize(envi.open(path / 'T23_real.bin.hdr', path / 'T23_real.bin').read_band(0) + \\\n",
        "                                1j * envi.open(path / 'T23_imag.bin.hdr', path / 'T23_imag.bin').read_band(0))\n",
        "        return T\n",
        "\n",
        "    @staticmethod\n",
        "    def open_s_dataset(path: str):\n",
        "        path = Path(path)\n",
        "        # http://www.spectralpython.net/fileio.html#envi-headers\n",
        "        s_11_meta = envi.open(path / 's11.bin.hdr', path / 's11.bin')\n",
        "        s_12_meta = envi.open(path / 's12.bin.hdr', path / 's12.bin')\n",
        "        s_21_meta = envi.open(path / 's21.bin.hdr', path / 's21.bin')\n",
        "        s_22_meta = envi.open(path / 's22.bin.hdr', path / 's22.bin')\n",
        "\n",
        "        s_11 = s_11_meta.read_band(0)\n",
        "        s_12 = s_12_meta.read_band(0)\n",
        "        s_21 = s_21_meta.read_band(0)\n",
        "        s_22 = s_22_meta.read_band(0)\n",
        "\n",
        "        assert np.all(s_21 == s_12)\n",
        "\n",
        "        return np.stack((s_11, s_12, s_22), axis=-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def open_dataset_t6(path: str):\n",
        "        path = Path(path)\n",
        "        first_read = standarize(envi.open(path / 'T11.bin.hdr', path / 'T11.bin').read_band(0))\n",
        "        T = np.zeros(first_read.shape + (21,), dtype=complex)\n",
        "\n",
        "        # Diagonal\n",
        "        T[:, :, 0] = first_read\n",
        "        T[:, :, 1] = standarize(envi.open(path / 'T22.bin.hdr', path / 'T22.bin').read_band(0))\n",
        "        T[:, :, 2] = standarize(envi.open(path / 'T33.bin.hdr', path / 'T33.bin').read_band(0))\n",
        "        T[:, :, 3] = standarize(envi.open(path / 'T44.bin.hdr', path / 'T44.bin').read_band(0))\n",
        "        T[:, :, 4] = standarize(envi.open(path / 'T55.bin.hdr', path / 'T55.bin').read_band(0))\n",
        "        T[:, :, 5] = standarize(envi.open(path / 'T66.bin.hdr', path / 'T66.bin').read_band(0))\n",
        "\n",
        "        T[:, :, 6] = standarize(envi.open(path / 'T12_real.bin.hdr', path / 'T12_real.bin').read_band(0) + \\\n",
        "                                1j * envi.open(path / 'T12_imag.bin.hdr', path / 'T12_imag.bin').read_band(0))\n",
        "        T[:, :, 7] = standarize(envi.open(path / 'T13_real.bin.hdr', path / 'T13_real.bin').read_band(0) + \\\n",
        "                                1j * envi.open(path / 'T13_imag.bin.hdr', path / 'T13_imag.bin').read_band(0))\n",
        "        T[:, :, 8] = standarize(envi.open(path / 'T14_real.bin.hdr', path / 'T14_real.bin').read_band(0) + \\\n",
        "                                1j * envi.open(path / 'T14_imag.bin.hdr', path / 'T14_imag.bin').read_band(0))\n",
        "        T[:, :, 9] = standarize(envi.open(path / 'T15_real.bin.hdr', path / 'T15_real.bin').read_band(0) + \\\n",
        "                                1j * envi.open(path / 'T15_imag.bin.hdr', path / 'T15_imag.bin').read_band(0))\n",
        "        T[:, :, 10] = standarize(envi.open(path / 'T16_real.bin.hdr', path / 'T16_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T16_imag.bin.hdr', path / 'T16_imag.bin').read_band(0))\n",
        "\n",
        "        T[:, :, 11] = standarize(envi.open(path / 'T23_real.bin.hdr', path / 'T23_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T23_imag.bin.hdr', path / 'T23_imag.bin').read_band(0))\n",
        "        T[:, :, 12] = standarize(envi.open(path / 'T24_real.bin.hdr', path / 'T24_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T24_imag.bin.hdr', path / 'T24_imag.bin').read_band(0))\n",
        "        T[:, :, 13] = standarize(envi.open(path / 'T25_real.bin.hdr', path / 'T25_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T25_imag.bin.hdr', path / 'T25_imag.bin').read_band(0))\n",
        "        T[:, :, 14] = standarize(envi.open(path / 'T26_real.bin.hdr', path / 'T26_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T26_imag.bin.hdr', path / 'T26_imag.bin').read_band(0))\n",
        "\n",
        "        T[:, :, 15] = standarize(envi.open(path / 'T34_real.bin.hdr', path / 'T34_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T34_imag.bin.hdr', path / 'T34_imag.bin').read_band(0))\n",
        "        T[:, :, 16] = standarize(envi.open(path / 'T35_real.bin.hdr', path / 'T35_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T35_imag.bin.hdr', path / 'T35_imag.bin').read_band(0))\n",
        "        T[:, :, 17] = standarize(envi.open(path / 'T36_real.bin.hdr', path / 'T36_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T36_imag.bin.hdr', path / 'T36_imag.bin').read_band(0))\n",
        "\n",
        "        T[:, :, 18] = standarize(envi.open(path / 'T45_real.bin.hdr', path / 'T45_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T45_imag.bin.hdr', path / 'T45_imag.bin').read_band(0))\n",
        "        T[:, :, 19] = standarize(envi.open(path / 'T46_real.bin.hdr', path / 'T46_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T46_imag.bin.hdr', path / 'T46_imag.bin').read_band(0))\n",
        "\n",
        "        T[:, :, 20] = standarize(envi.open(path / 'T56_real.bin.hdr', path / 'T56_real.bin').read_band(0) + \\\n",
        "                                 1j * envi.open(path / 'T56_imag.bin.hdr', path / 'T56_imag.bin').read_band(0))\n",
        "        return T\n",
        "\n",
        "    # Debug\n",
        "    def print_ground_truth(self, label: Optional = None, path=None, t=None, mask: Optional = None, ax=None):\n",
        "        if label is None:\n",
        "            label = self.get_labels()\n",
        "        if mask is None:\n",
        "            mask = self.get_sparse_labels()\n",
        "        return pauli_rgb_map_plot(label, mask=mask, dataset_name=self.name, t=t if self.mode == \"t\" else None,\n",
        "                                  path=path, ax=ax)\n",
        "\n",
        "\n",
        "EPOCHS = 1\n",
        "DROPOUT_DEFAULT = {\n",
        "    \"downsampling\": None,\n",
        "    \"bottle_neck\": None,\n",
        "    \"upsampling\": None\n",
        "}\n",
        "\n",
        "DATASET_META = {\n",
        "    \"SF-AIRSAR\": {\"classes\": 5, \"orientation\": \"vertical\", \"percentage\": (0.8, 0.2)},\n",
        "    # \"SF-ALOS2\": {\"classes\": 6, \"orientation\": \"vertical\", \"percentage\": (0.8, 0.2)},\n",
        "    # \"SF-GF3\": {\"classes\": 6, \"orientation\": \"vertical\", \"percentage\": (0.8, 0.2)},\n",
        "    # \"SF-RISAT\": {\"classes\": 6, \"orientation\": \"vertical\", \"percentage\": (0.8, 0.2)},\n",
        "    \"SF-RS2\": {\"classes\": 5, \"orientation\": \"vertical\", \"percentage\": (0.8, 0.2)},\n",
        "    \"OBER\": {\"classes\": 3, \"orientation\": \"vertical\", \"percentage\": (0.85, 0.15)}\n",
        "}\n",
        "\n",
        "MODEL_META = {\n",
        "    \"fcnn\": {\"size\": 128, \"stride\": 25, \"pad\": 0, \"batch_size\": 30,\n",
        "            \"percentage\": (0.8, 0.1, 0.1), \"task\": \"segmentation\"},\n",
        "    \"cnn\": {\"size\": 12, \"stride\": 1, \"pad\": 'same', \"batch_size\": 100,\n",
        "              \"percentage\": (0.09, 0.01, 0.9), \"task\": \"classification\"},\n",
        "    \"mlp\": {\"size\": 1, \"stride\": 1, \"pad\": 'same', \"batch_size\": 100,\n",
        "                \"percentage\": (0.02, 0.08, 0.9), \"task\": \"classification\"},\n",
        "    \"3d-cnn\": {\"size\": 12, \"stride\": 1, \"pad\": 'same', \"batch_size\": 64,\n",
        "            \"percentage\": (0.09, 0.01, 0.9), \"task\": \"classification\"}\n",
        "}\n",
        "\n",
        "\n",
        "def get_callbacks_list(early_stop, temp_path):\n",
        "    tensorboard_callback = callbacks.TensorBoard(log_dir=temp_path / 'tensorboard', histogram_freq=0)\n",
        "    cp_callback = callbacks.ModelCheckpoint(filepath=temp_path / 'checkpoints/cp.ckpt', save_weights_only=True,\n",
        "                                            verbose=0, save_best_only=True)\n",
        "    callback_list = [tensorboard_callback, cp_callback]\n",
        "    if early_stop:\n",
        "        if isinstance(early_stop, int):\n",
        "            patience = early_stop\n",
        "        else:\n",
        "            patience = 5\n",
        "        callback_list.append(callbacks.EarlyStopping(\n",
        "            monitor='val_loss', patience=patience, restore_best_weights=False\n",
        "        ))\n",
        "    return callback_list\n",
        "\n",
        "\n",
        "def dropout_type(arg):\n",
        "    if arg == 'None' or arg == 'none':\n",
        "        f = None\n",
        "    else:\n",
        "        try:\n",
        "            f = float(arg)\n",
        "        except ValueError:\n",
        "            raise argparse.ArgumentTypeError(\"Must be a floating point number\")\n",
        "        if f > 1. or f < 0.:\n",
        "            raise argparse.ArgumentTypeError(\"Argument must be < \" + str(1) + \" and > \" + str(0))\n",
        "    return f\n",
        "\n",
        "\n",
        "def parse_input():\n",
        "    parser = argparse.ArgumentParser(formatter_class=RawTextHelpFormatter)\n",
        "    parser.add_argument('--dataset_method', nargs=1, default=[\"random\"], type=str,\n",
        "                        help='One of:\\n\\t- random (default): randomly select the train and val set\\n'\n",
        "                             '\\t- separate: split first the image into sections and select the sets from there\\n'\n",
        "                             '\\t- single_separated_image: as separate, but do not apply the slinding window operation '\n",
        "                             '\\n\\t\\t(no batches, only one image per set). \\n\\t\\tOnly possible with segmentation models')\n",
        "    parser.add_argument('--tensorflow', action='store_true', help='Use tensorflow library')\n",
        "    parser.add_argument('--epochs', nargs=1, type=int, default=[EPOCHS], help='(int) epochs to be done')\n",
        "    parser.add_argument('--model', nargs=1, type=str, default=[\"cao\"],\n",
        "                        help='deep model to be used. Options:\\n' +\n",
        "                             \"\".join([f\"\\t- {model}\\n\" for model in MODEL_META.keys()]))\n",
        "    parser.add_argument('--early_stop', nargs='?', const=True, default=False, type=early_stop_type,\n",
        "                        help='Apply early stopping to training')\n",
        "    parser.add_argument('--balance', nargs=1, type=str, default=[\"None\"], help='Deal with unbalanced dataset by:\\n'\n",
        "                                                                               '\\t- loss: weighted loss\\n'\n",
        "                                                                               '\\t- dataset: balance dataset by '\n",
        "                                                                               'randomly remove pixels of '\n",
        "                                                                               'predominant classes\\n'\n",
        "                                                                               '\\t- any other string will be considered'\n",
        "                                                                               ' as not balanced')\n",
        "    parser.add_argument('--real_mode', type=str, nargs='?', const='real_imag', default='complex',\n",
        "                        help='run real model instead of complex.\\nIf [REAL_MODE] is used it should be one of:\\n'\n",
        "                             '\\t- real_imag\\n\\t- amplitude_phase\\n\\t- amplitude_only\\n\\t- real_only')\n",
        "    parser.add_argument('--dropout', nargs=3, type=dropout_type, default=[None, None, None],\n",
        "                        help='dropout rate to be used on '\n",
        "                             'downsampling, bottle neck, upsampling sections (in order). '\n",
        "                             'Example: `python main.py --dropout 0.1 None 0.3` will use 10%% dropout on the '\n",
        "                             'downsampling part and 30%% on the upsamlpling part and no dropout on the bottle neck.')\n",
        "    parser.add_argument('--coherency', action='store_true', help='Use coherency matrix instead of s')\n",
        "    parser.add_argument(\"--dataset\", nargs=1, type=str, default=[\"SF-AIRSAR\"],\n",
        "                        help=\"dataset to be used. Available options:\\n\" +\n",
        "                             \"\".join([f\"\\t- {dataset}\\n\" for dataset in DATASET_META.keys()]))\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "def early_stop_type(arg):\n",
        "    if isinstance(arg, bool):\n",
        "        return arg\n",
        "    else:\n",
        "        return int(arg)\n",
        "\n",
        "\n",
        "def _get_dataset_handler(dataset_name: str, mode, complex_mode, real_mode, balance: bool, normalize: bool = False,\n",
        "                         classification: bool = False):\n",
        "    dataset_name = dataset_name.upper()\n",
        "    if dataset_name.startswith(\"SF\"):\n",
        "        dataset_handler = SanFranciscoDataset(dataset_name=dataset_name, mode=mode, balance_dataset=balance,\n",
        "                                              complex_mode=complex_mode, real_mode=real_mode, normalize=normalize,\n",
        "                                              classification=classification)\n",
        "    elif dataset_name == \"OBER\":\n",
        "        if mode != \"t\":\n",
        "            raise ValueError(f\"Oberfaffenhofen only supports data as coherency matrix (t). Asked for {mode}\")\n",
        "        dataset_handler = OberpfaffenhofenDataset(complex_mode=complex_mode, real_mode=real_mode, normalize=normalize,\n",
        "                                                  balance_dataset=balance, classification=classification)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown dataset {dataset_name}\")\n",
        "    return dataset_handler\n",
        "\n",
        "\n",
        "def _get_model(model_name: str, channels: int, weights: Optional[List[float]], real_mode: str, num_classes: int,\n",
        "               dropout, complex_mode: bool = True, tensorflow: bool = False):\n",
        "    model_name = model_name.lower()\n",
        "    if complex_mode:\n",
        "        name_prefix = \"cv-\"\n",
        "        dtype = np.complex64\n",
        "        if tensorflow:\n",
        "            raise ValueError(\"Tensorflow library does not support complex mode\")\n",
        "    else:\n",
        "        name_prefix = \"rv-\"\n",
        "        dtype = np.float32\n",
        "        channels = REAL_CAST_MODES[real_mode] * channels\n",
        "    if model_name == \"cao\":\n",
        "        model = get_cao_fcnn_model(input_shape=(None, None, channels), num_classes=num_classes,\n",
        "                                   tensorflow=tensorflow, dropout_dict=dropout,\n",
        "                                   dtype=dtype, name=name_prefix + model_name, weights=weights)\n",
        "    elif model_name == \"zhang\":\n",
        "        if weights is not None:\n",
        "            print(\"WARNING: Zhang model does not support weighted loss\")\n",
        "        model = get_zhang_cnn_model(input_shape=(MODEL_META[\"zhang\"][\"size\"], MODEL_META[\"zhang\"][\"size\"], channels),\n",
        "                                    num_classes=num_classes, tensorflow=tensorflow, dtype=dtype,\n",
        "                                    dropout=dropout[\"downsampling\"],\n",
        "                                    name=name_prefix + model_name)\n",
        "    elif model_name == 'haensch':\n",
        "        if weights is not None:\n",
        "            print(\"WARNING: Haensch model does not support weighted loss\")\n",
        "        model = get_haensch_mlp_model(input_shape=(MODEL_META[\"haensch\"][\"size\"],\n",
        "                                                   MODEL_META[\"haensch\"][\"size\"], channels),\n",
        "                                      num_classes=num_classes, tensorflow=tensorflow, dtype=dtype,\n",
        "                                      dropout=dropout[\"downsampling\"],\n",
        "                                      name=name_prefix + model_name)\n",
        "    elif model_name == 'tan':\n",
        "        if weights is not None:\n",
        "            print(\"WARNING: Tan model does not support weighted loss\")\n",
        "        model = get_tan_3d_cnn_model(input_shape=(MODEL_META[\"tan\"][\"size\"],\n",
        "                                                  MODEL_META[\"tan\"][\"size\"], channels),\n",
        "                                     num_classes=num_classes, tensorflow=tensorflow, dtype=dtype,\n",
        "                                     name=name_prefix + model_name)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model {model_name}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def open_saved_model(root_path, model_name: str, complex_mode: bool, weights, channels: int, dropout,\n",
        "                     real_mode: str, tensorflow: bool, num_classes: int):\n",
        "    if isinstance(root_path, str):\n",
        "        root_path = Path(root_path)\n",
        "    model = _get_model(model_name=model_name, tensorflow=tensorflow, dropout=dropout,\n",
        "                       channels=channels, weights=weights, real_mode=real_mode,\n",
        "                       complex_mode=complex_mode, num_classes=num_classes)\n",
        "    model.load_weights(str(root_path / \"checkpoints/cp.ckpt\"))\n",
        "    return model\n",
        "\n",
        "\n",
        "def _final_result_segmentation(root_path, use_mask, dataset_handler, model):\n",
        "    full_image = dataset_handler.get_image()\n",
        "    seg = dataset_handler.get_labels()\n",
        "    if not dataset_handler.complex_mode:\n",
        "        full_image, seg = transform_to_real_map_function(full_image, seg)\n",
        "    # I pad to make sure dimensions are Ok when downsampling and upsampling again.\n",
        "    first_dim_pad = int(2 ** 5 * np.ceil(full_image.shape[0] / 2 ** 5)) - full_image.shape[0]\n",
        "    second_dim_pad = int(2 ** 5 * np.ceil(full_image.shape[1] / 2 ** 5)) - full_image.shape[1]\n",
        "    paddings = [\n",
        "        [int(np.ceil(first_dim_pad / 2)), int(np.floor(first_dim_pad / 2))],\n",
        "        [int(np.ceil(second_dim_pad / 2)), int(np.floor(second_dim_pad / 2))],\n",
        "        [0, 0]\n",
        "    ]\n",
        "    if use_mask:\n",
        "        mask = dataset_handler.get_sparse_labels()\n",
        "        mask = tf.pad(mask, paddings[:-1])\n",
        "    else:\n",
        "        mask = None\n",
        "    full_image = tf.pad(full_image, paddings)\n",
        "    seg = tf.pad(seg, paddings)\n",
        "    full_image = tf.expand_dims(full_image, axis=0)  # add batch axis\n",
        "    seg = tf.expand_dims(seg, axis=0)\n",
        "\n",
        "    prediction = model.predict(full_image)[0]\n",
        "    if os.path.isfile(str(root_path / 'evaluate.csv')):\n",
        "        evaluate = _eval_list_to_dict(model.evaluate(full_image, seg), model.metrics_names)\n",
        "        eval_df = pd.read_csv(str(root_path / 'evaluate.csv'), index_col=0)\n",
        "        eval_df = pd.concat([eval_df, DataFrame.from_dict({'full_set': evaluate})], axis=1)\n",
        "        eval_df.to_csv(str(root_path / 'evaluate.csv'))\n",
        "    if tf.dtypes.as_dtype(prediction.dtype).is_complex:\n",
        "        prediction = (tf.math.real(prediction) + tf.math.imag(prediction)) / 2.\n",
        "    labels_to_rgb(prediction, savefig=str(root_path / \"prediction\"), mask=mask, colors=COLORS[dataset_handler.name])\n",
        "\n",
        "\n",
        "def _final_result_classification(root_path, use_mask, dataset_handler, model):\n",
        "    shape = model.input.shape[1:]\n",
        "    stride = 1\n",
        "    tiles, label_tiles = dataset_handler.apply_sliding(stride=stride, size=shape[:-1], pad=\"same\", classification=True)\n",
        "    # set_trace()\n",
        "    if not dataset_handler.complex_mode:\n",
        "        tiles, label_tiles = transform_to_real_map_function(tiles, label_tiles, dataset_handler.real_mode)\n",
        "    if use_mask:\n",
        "        mask = dataset_handler.get_sparse_labels()\n",
        "    else:\n",
        "        mask = None\n",
        "    prediction = model.predict(tiles)\n",
        "    if os.path.isfile(str(root_path / 'evaluate.csv')):\n",
        "        evaluate = _eval_list_to_dict(model.evaluate(tiles, label_tiles), model.metrics_names)\n",
        "        eval_df = pd.read_csv(str(root_path / 'evaluate.csv'), index_col=0)\n",
        "        eval_df = pd.concat([eval_df, DataFrame.from_dict({'full_set': evaluate})], axis=1)\n",
        "        eval_df.to_csv(str(root_path / 'evaluate.csv'))\n",
        "    if tf.dtypes.as_dtype(prediction.dtype).is_complex:\n",
        "        prediction = (tf.math.real(prediction) + tf.math.imag(prediction)) / 2.\n",
        "    # set_trace()\n",
        "    image_prediction = tf.reshape(prediction,\n",
        "                                  shape=tuple(dataset_handler.get_image().shape[:-1]) + (prediction.shape[-1],))\n",
        "    labels_to_rgb(image_prediction, savefig=str(root_path / \"prediction\"), mask=mask,\n",
        "                  colors=COLORS[dataset_handler.name])\n",
        "\n",
        "\n",
        "def get_final_model_results(root_path, model_name: str,\n",
        "                            dataset_handler,  # dataset parameters\n",
        "                            dropout, channels: int = 3,  # model hyper-parameters\n",
        "                            complex_mode: bool = True, real_mode: str = \"real_imag\",  # cv / rv format\n",
        "                            use_mask: bool = True, tensorflow: bool = False):\n",
        "    model = open_saved_model(root_path, model_name=model_name, complex_mode=complex_mode,\n",
        "                             weights=None,  # I am not training, so no need to use weights in the loss function here\n",
        "                             channels=channels, real_mode=real_mode, dropout=dropout,\n",
        "                             tensorflow=tensorflow, num_classes=DATASET_META[dataset_handler.name][\"classes\"])\n",
        "    if MODEL_META[model_name]['task'] == 'segmentation':\n",
        "        _final_result_segmentation(root_path=root_path, model=model, dataset_handler=dataset_handler, use_mask=use_mask)\n",
        "    elif MODEL_META[model_name]['task'] == 'classification':\n",
        "        _final_result_classification(root_path=root_path, model=model, dataset_handler=dataset_handler,\n",
        "                                     use_mask=use_mask)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown task {MODEL_META[model_name]['task']}\")\n",
        "\n",
        "\n",
        "def _eval_list_to_dict(evaluate, metrics):\n",
        "    return_dict = {}\n",
        "    for i, m in enumerate(metrics):\n",
        "        return_dict[m] = evaluate[i]\n",
        "    return return_dict\n",
        "\n",
        "\n",
        "def _get_confusion_matrix(ds, model, num_classes):\n",
        "    # x_input, y_true = np.concatenate([x for x, y in ds], axis=0), np.concatenate([y for x, y in ds], axis=0)\n",
        "    x_input, y_true = ds\n",
        "    prediction = model.predict(x_input)\n",
        "    if tf.dtypes.as_dtype(prediction.dtype).is_complex:\n",
        "        real_prediction = (tf.math.real(prediction) + tf.math.imag(prediction)) / 2.\n",
        "    else:\n",
        "        real_prediction = prediction\n",
        "    real_flatten_prediction = tf.reshape(real_prediction, shape=[-1, num_classes])\n",
        "    flatten_y_true = tf.reshape(y_true, shape=[-1, num_classes])\n",
        "    mask = np.invert(np.all(flatten_y_true == 0, axis=1))\n",
        "    flatten_filtered_y_true = tf.boolean_mask(flatten_y_true, mask)\n",
        "    filtered_y_pred = tf.boolean_mask(real_flatten_prediction, mask)\n",
        "    sparse_flatten_filtered_y_true = tf.argmax(filtered_y_pred, axis=-1)\n",
        "    sparse_flatten_filtered_y_pred = tf.argmax(flatten_filtered_y_true, axis=-1)\n",
        "    conf = tf.math.confusion_matrix(labels=sparse_flatten_filtered_y_true, predictions=sparse_flatten_filtered_y_pred)\n",
        "    conf_df = DataFrame(data=conf.numpy())\n",
        "    conf_df['Total'] = conf_df.sum(axis=1)\n",
        "    conf_df.loc['Total'] = conf_df.sum(axis=0)\n",
        "    # one = model.evaluate(x=x_input, y=y_true, batch_size=30)\n",
        "    # two = model.evaluate(ds)\n",
        "    # set_trace()\n",
        "    return conf_df\n",
        "\n",
        "\n",
        "def run_model(model_name: str, balance: str, tensorflow: bool,\n",
        "              mode: str, complex_mode: bool, real_mode: str,\n",
        "              early_stop: Union[bool, int], epochs: int, temp_path, dropout,\n",
        "              dataset_name: str, dataset_method: str, percentage: Optional[Union[Tuple[float], float]] = None,\n",
        "              debug: bool = False):\n",
        "    if percentage is None:\n",
        "        if dataset_method == \"random\":\n",
        "            percentage = MODEL_META[model_name][\"percentage\"]\n",
        "        else:\n",
        "            percentage = DATASET_META[dataset_name][\"percentage\"]\n",
        "    # Dataset\n",
        "    dataset_name = dataset_name.upper()\n",
        "    mode = mode.lower()\n",
        "    dataset_handler = _get_dataset_handler(dataset_name=dataset_name, mode=mode,\n",
        "                                           complex_mode=complex_mode, real_mode=real_mode, normalize=False,\n",
        "                                           balance=(balance == \"dataset\"),\n",
        "                                           classification=MODEL_META[model_name]['task'] == 'classification')\n",
        "    ds_list = dataset_handler.get_dataset(method=dataset_method,\n",
        "                                          percentage=percentage,\n",
        "                                          size=MODEL_META[model_name][\"size\"], stride=MODEL_META[model_name][\"stride\"],\n",
        "                                          pad=MODEL_META[model_name][\"pad\"],\n",
        "                                          shuffle=True, savefig=str(temp_path / \"image_\") if debug else None,\n",
        "                                          orientation=DATASET_META[dataset_name]['orientation'],\n",
        "                                          data_augment=False,\n",
        "                                          batch_size=MODEL_META[model_name]['batch_size'], use_tf_dataset=False\n",
        "                                          )\n",
        "    train_ds = ds_list[0]\n",
        "    if len(ds_list) > 1:\n",
        "        val_ds = ds_list[1]\n",
        "    else:\n",
        "        val_ds = None\n",
        "    if len(ds_list) > 2:\n",
        "        test_ds = ds_list[2]\n",
        "    else:\n",
        "        test_ds = None\n",
        "    if debug:\n",
        "        dataset_handler.print_ground_truth(path=temp_path)\n",
        "    # Model\n",
        "    weights = dataset_handler.get_weights()\n",
        "    model = _get_model(model_name=model_name,\n",
        "                       channels=3 if mode == \"s\" else 6,  # TODO: isn't 'k' an option?\n",
        "                       weights=weights if balance == \"loss\" else None,\n",
        "                       real_mode=real_mode, num_classes=DATASET_META[dataset_name][\"classes\"],\n",
        "                       complex_mode=complex_mode, tensorflow=tensorflow, dropout=dropout)\n",
        "    callbacks = get_callbacks_list(early_stop, temp_path)\n",
        "    # Training\n",
        "    history = model.fit(x=train_ds[0], y=train_ds[1], epochs=epochs, batch_size=MODEL_META[model_name]['batch_size'],\n",
        "                        validation_data=val_ds, shuffle=True, callbacks=callbacks)\n",
        "    df = DataFrame.from_dict(history.history)\n",
        "    # Get best model\n",
        "    # checkpoint_model = model\n",
        "    checkpoint_model = open_saved_model(temp_path, model_name=model_name, complex_mode=complex_mode,\n",
        "                                        weights=weights if balance == \"loss\" else None,\n",
        "                                        channels=3 if mode == \"s\" else 6, dropout=dropout, real_mode=real_mode,\n",
        "                                        tensorflow=tensorflow, num_classes=DATASET_META[dataset_name][\"classes\"])\n",
        "    evaluate = {'train': _eval_list_to_dict(evaluate=checkpoint_model.evaluate(train_ds[0], train_ds[1],\n",
        "                                                                               batch_size=MODEL_META[model_name][\n",
        "                                                                                   'batch_size']),\n",
        "                                            metrics=checkpoint_model.metrics_names)}\n",
        "    train_confusion_matrix = _get_confusion_matrix(train_ds, checkpoint_model, DATASET_META[dataset_name][\"classes\"])\n",
        "    train_confusion_matrix.to_csv(str(temp_path / 'train_confusion_matrix.csv'))\n",
        "    if val_ds:\n",
        "        evaluate['val'] = _eval_list_to_dict(evaluate=checkpoint_model.evaluate(val_ds[0], val_ds[1]),\n",
        "                                             metrics=checkpoint_model.metrics_names)\n",
        "        val_confusion_matrix = _get_confusion_matrix(val_ds, checkpoint_model, DATASET_META[dataset_name][\"classes\"])\n",
        "        val_confusion_matrix.to_csv(str(temp_path / 'val_confusion_matrix.csv'))\n",
        "    if test_ds:\n",
        "        evaluate['test'] = _eval_list_to_dict(evaluate=checkpoint_model.evaluate(test_ds[0], test_ds[1]),\n",
        "                                              metrics=checkpoint_model.metrics_names)\n",
        "        test_confusion_matrix = _get_confusion_matrix(test_ds, checkpoint_model, DATASET_META[dataset_name][\"classes\"])\n",
        "        test_confusion_matrix.to_csv(str(temp_path / 'test_confusion_matrix.csv'))\n",
        "    eval_df = DataFrame.from_dict(evaluate)\n",
        "    return df, dataset_handler, eval_df\n",
        "\n",
        "\n",
        "def parse_dropout(dropout):\n",
        "    if dropout is None:\n",
        "        dropout = {\n",
        "            \"downsampling\": None,\n",
        "            \"bottle_neck\": None,\n",
        "            \"upsampling\": None\n",
        "        }\n",
        "    elif isinstance(dropout, float):\n",
        "        dropout = {\n",
        "            \"downsampling\": dropout,\n",
        "            \"bottle_neck\": dropout,\n",
        "            \"upsampling\": dropout\n",
        "        }\n",
        "    elif isinstance(dropout, list):\n",
        "        assert len(dropout) == 3, f\"Dropout list should be of length 3, received {len(dropout)}\"\n",
        "        dropout = {\n",
        "            \"downsampling\": dropout[0],\n",
        "            \"bottle_neck\": dropout[1],\n",
        "            \"upsampling\": dropout[2]\n",
        "        }\n",
        "    elif not isinstance(dropout, dict):\n",
        "        raise ValueError(f\"Unknown dataset format {dropout}\")\n",
        "    if \"downsampling\" not in dropout.keys():\n",
        "        raise ValueError(f\"downsampling should be a dropout key. dropout keys: {dropout.keys()}\")\n",
        "    if \"bottle_neck\" not in dropout.keys():\n",
        "        raise ValueError(f\"bottle_neck should be a dropout key. dropout keys: {dropout.keys()}\")\n",
        "    if \"upsampling\" not in dropout.keys():\n",
        "        raise ValueError(f\"upsampling should be a dropout key. dropout keys: {dropout.keys()}\")\n",
        "    return dropout\n",
        "\n",
        "\n",
        "def run_wrapper(model_name: str, balance: str, tensorflow: bool,\n",
        "                mode: str, complex_mode: bool, real_mode: str,\n",
        "                early_stop: Union[int, bool], epochs: int,\n",
        "                dataset_name: str, dataset_method: str, dropout,\n",
        "                percentage: Optional[Union[Tuple[float], float]] = None, debug: bool = False):\n",
        "    temp_path = create_folder(\"./log/\")\n",
        "    makedirs(temp_path, exist_ok=True)\n",
        "    dropout = parse_dropout(dropout=dropout)\n",
        "    with open(temp_path / 'model_summary.txt', 'w+') as summary_file:\n",
        "        summary_file.write(\" \".join(sys.argv[1:]) + \"\\n\")\n",
        "        summary_file.write(f\"Model: {'cv-' if complex_mode else 'rv-'}{model_name}\\n\")\n",
        "        if not complex_mode:\n",
        "            summary_file.write(f\"\\t{real_mode}\\n\")\n",
        "        summary_file.write(f\"Dataset: {dataset_name}:\\t{mode}\\n\")\n",
        "        summary_file.write(f\"Other parameters:\\n\")\n",
        "        summary_file.write(f\"\\tepochs: {epochs}\\n\")\n",
        "        summary_file.write(f\"\\t{'' if early_stop else 'no'} early stop\\n\")\n",
        "        summary_file.write(f\"\\tweighted {balance}\\n\")\n",
        "    df, dataset_handler, eval_df = run_model(model_name=model_name, balance=balance, tensorflow=tensorflow,\n",
        "                                             mode=mode, complex_mode=complex_mode, real_mode=real_mode,\n",
        "                                             early_stop=early_stop, temp_path=temp_path, epochs=epochs,\n",
        "                                             dataset_name=dataset_name, dataset_method=dataset_method,\n",
        "                                             percentage=percentage, debug=debug, dropout=dropout)\n",
        "    df.to_csv(str(temp_path / 'history_dict.csv'), index_label=\"epoch\")\n",
        "    eval_df.to_csv(str(temp_path / 'evaluate.csv'))\n",
        "    get_final_model_results(temp_path, dataset_handler=dataset_handler, model_name=model_name,\n",
        "                            tensorflow=tensorflow, complex_mode=complex_mode, real_mode=real_mode,\n",
        "                            channels=3 if mode == \"s\" else 6, dropout=dropout)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_input()\n",
        "    run_wrapper(model_name=args.model[0], balance=args.balance[0], tensorflow=args.tensorflow,\n",
        "                mode=\"t\" if args.coherency else \"s\", complex_mode=True if args.real_mode == 'complex' else False,\n",
        "                real_mode=args.real_mode, early_stop=args.early_stop, epochs=args.epochs[0],\n",
        "                dataset_name=args.dataset[0], dataset_method=args.dataset_method[0], percentage=None,\n",
        "                dropout=args.dropout)"
      ]
    }
  ]
}